# -*- coding: utf-8 -*-
"""movie_recommend_system_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JbCE165FN9JEUbH-HO9g_xQCjphptk0-
"""

import numpy as np
import pandas as pd

"""#**step 1: dataset upload**"""

from google.colab import drive
drive.mount('/content/drive')

movies = pd.read_csv('/content/drive/MyDrive/tmdb_5000_movies.csv')

movies

movies['genres'][0]

credits = pd.read_csv('/content/drive/MyDrive/tmdb_5000_credits.csv')
credits

movies.head()

movies.shape

credits.head()

credits.crew[0]



"""**data merge**"""

movies = movies.merge(credits,on='title')

movies.head()
# budget
# homepage
# id
# original_language
# original_title
# popularity
# production_comapny
# production_countries
# release-date(not sure)

movies.info()

"""#**step 2: data preproccesing**

**select only require portion**
"""

movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]

movies.head()

"""**check in each column have null or missing value**"""

movies.isnull().sum()

"""**check duplicate data**"""

movies.duplicated().sum()

movies.iloc[0].genres

# is a string of list of dictionary so we convert into the  list of dictionary by using ast
import ast
ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

# we fetch the name dictionary from the list of dictonary and append into the  " L" list only contain name
def convert(text):
    L = []
    for i in ast.literal_eval(text):
        L.append(i['name'])
    return L



# use drop row if the some value are missing of null present
movies.dropna(inplace=True)

movies['genres'] = movies['genres'].apply(convert)
movies.head()

movies['keywords'] = movies['keywords'].apply(convert)
movies.head()

# check now so we include only top 3 - 5  casting actor in my data
movies['cast'][0]

# we include only top three casting actor  so we fetch the name of the casting actor from the list of dic of the  cast
def convert3(text):
    L = []
    counter = 0
    for i in ast.literal_eval(text):
        if counter < 5:
            L.append(i['name'])
        counter+=1
    return L

movies['cast'] = movies['cast'].apply(convert3)
movies.head()



movies['cast'] = movies['cast'].apply(lambda x:x[0:5])

(movies['crew'][0])

# we fetch only director namefrom the crew meneber so we cheack first  where job = director wali dic ko  hi lena hai
def fetch_director(text):
    L = []
    for i in ast.literal_eval(text):
        if i['job'] == 'Director':
            L.append(i['name'])
    return L

movies['crew'] = movies['crew'].apply(fetch_director)

# overview is a string so first we split and stor in a list
movies['overview'][0]

import pandas as pd
movies['overview'] = movies['overview'].apply(lambda x:x.split())
# movies.sample(5)

# now in every  column if the name or any word like name is present like James Cameron so we remove the space btwn them
# bsc on othore movie also may be present   partial part  and if we convert in vector then he consider 2 word so better we  make single word
def collapse(L):
    L1 = []
    for i in L:
        L1.append(i.replace(" ",""))
    return L1

movies['cast'] = movies['cast'].apply(collapse)
movies['crew'] = movies['crew'].apply(collapse)
movies['genres'] = movies['genres'].apply(collapse)
movies['keywords'] = movies['keywords'].apply(collapse)

movies.head()

# we make the tag  by merge the all column
movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

# after merge we drop the  column which is used in merging
new = movies.drop(columns=['overview','keywords','cast','crew'])
#new.head()

# this tag is present in list
new.head()

# so we convert the list, into a string
new['tags'] = new['tags'].apply(lambda x: " ".join(x))

new.head()

movies['tags'][0]

import nltk

# but there are some problem in the data  in the tag some word have same meaning but  show diff like : actor,actors,   love,loved loving
from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()

def stem(text):
  x=[]

  for i in text.split():
    x.append(ps.stem(i))
  return " ".join(x)   # again convert into the string from the list

new['tags']=new['tags'].apply(stem)



# here we use max_fearture =5000 means most common used word top 5000 word in the collection of tag
# and remove the  stopword
# we make the cv obj
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,stop_words='english')

"""##**STEP 3: MODEL APPLY ON THE DATA**

# **BAG_OF_WORD MODEL**
"""

# by default bhout sari value zero hogi and by default sparse matrix return krega so ham use  numpy array me convert kr lenge
vector = cv.fit_transform(new['tags']).toarray()

vector.shape

vector

# isme  love ,loved ,danse,dansed type word h to ham   love and dans ,e convert kr rhe h upr steming  model se
cv.get_feature_names_out()

# we use cosine sismilarity library
# which is apply on the vector  and calculate the cosine value  jitna  jyada value hoga vector utna similor hoga
from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vector)

similarity.shape

similarity

# this is use the  fetch the index of given movie
new[new['title'] == 'The Lego Movie'].index[0]

# now the such a problem  if we find the top 5 high value in the similarity vector corresponding given index
# so we neew to sort , if we sorting then we loos the index position of the sililarity vector bcs
#  in the similarity vector every index showing the value of this movie with the recoomend movie
# so we use enumerate fun which is hold the index position in the similarity vector ans we can sort on the basis of value
# and we use "key = lambda x: x[1]" bcs by defult wo index ke base pr sort kr rha tha so iske likhne se fir wo value ke base pr sort krega
index = new[new['title'] =='Gandhi' ].index[0]
index    #2030 is a index of gandhi movie

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder

def recommend_movies(movie_names, top_n=5):
    # Vectorize given movie names using TF-IDF vectorizer
    given_movie_vectors = cv.transform(movie_names)

    # Compute cosine similarity with training data TF-IDF vectors
    cos_sim_given_movies = cosine_similarity(given_movie_vectors, vector)

    # Compute mean cosine similarity scores for given movies
    mean_scores = np.mean(cos_sim_given_movies, axis=0)

    # Get indices of top n movies with highest similarity scores
    top_indices = np.argsort(mean_scores)[::-1][:top_n]

    # Recommend top n movies
    recommended_movies = [(title[i], mean_scores[i]) for i in top_indices]
    return recommended_movies

# Example: Recommend 5 movies similar to "Inception" (not present in X_train)
given_movie_name = ["Inception"]
recommended_movies = recommend_movies(given_movie_name, top_n=5)
print("Recommended Movies:")
for movie, similarity_score in recommended_movies:
    print(f"{movie}: Similarity Score = {similarity_score:.4f}")

def recommend(movie,top_n=5):
  try:
    index = new[new['title'] == movie].index[0] # this is give the index of this movie and index[0] means 1st colum of the data table
    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])  #gives a simi vector on sorted based on value here we use key for sorting based on value
    for i in distances[1:6]:  # top 5 movie
            print(new.iloc[i[0]].title)  # i[0] means we fetch the index or  similarity me index position  for using the fetch  movie name
  except:
    print("No movie name found")

recommend('Gandhi')

"""#**TF_IDF_MODEL**"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer()
tfidf_movies = tfidf.fit_transform((new['tags'])).toarray()

similarity1 = cosine_similarity(tfidf_movies)

similarity1

# from sklearn.metrics import confusion_matrix
# y_pred_bow = np.argmax(similarity, axis=1)
# y_pred_tfidf = np.argmax(similarity1, axis=1)

# # Evaluate performance using confusion matrix
# confusion_matrix_bow = confusion_matrix(similarity, y_pred_bow)
# confusion_matrix_tfidf = confusion_matrix(similarity1, y_pred_tfidf)

def recommendations(movie):
  try:
    index = new[new['title'] == movie].index[0] # this is give the index of this movie and index[0] means 1st colum of the data table
    distances = sorted(list(enumerate(similarity1[index])),reverse=True,key = lambda x: x[1])  #gives a simi vector on sorted based on value here we use key for sorting based on value
    for i in distances[1:6]:  # top 5 movie
        print(new.iloc[i[0]].title)  # i[0] means we fetch the index or  similarity me index position  for using the fetch  movie name

  except:
    print("No movie name found")

recommendations("Gandhi")

from sklearn.feature_extraction.text import CountVectorizer

# Create the Bag of Words vectorizer
# bow_vectorizer = CountVectorizer()

# Fit and transform the documents
# bow_matrix = bow_vectorizer.fit_transform(documents)

from sklearn.feature_extraction.text import TfidfVectorizer

# Create the TF-IDF vectorizer
# tfidf_vectorizer = TfidfVectorizer()

# Fit and transform the documents
# tfidf_matrix = tfidf_vectorizer.fit_transform(documents)

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Assuming 'labels' is a list of class labels for each document
# X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, labels, test_size=0.2, random_state=42)

# Create a Naive Bayes classifier
# classifier = MultinomialNB()

# Train the classifier
# classifier.fit(X_train, y_train)

# Make predictions on the test set
# predictions_tfidf = classifier.predict(X_test)

# Calculate accuracy for TF-IDF
# accuracy_tfidf = accuracy_score(y_test, predictions_tfidf)

# # Repeat the process for Bag of Words
# X_train_bow, X_test_bow, _, _ = train_test_split(bow_matrix, labels, test_size=0.2, random_state=42)
# classifier_bow = MultinomialNB()
# classifier_bow.fit(X_train_bow, y_train)
# predictions_bow = classifier_bow.predict(X_test_bow)
# accuracy_bow = accuracy_score(y_test, predictions_bow)

# print("Accuracy - TF-IDF:", accuracy_tfidf)
# print("Accuracy - Bag of Words:", accuracy_bow)